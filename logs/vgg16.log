nohup: ignoring input
VGG(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): ReLU(inplace=True)
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (6): ReLU(inplace=True)
    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): ReLU(inplace=True)
    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace=True)
    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (13): ReLU(inplace=True)
    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): ReLU(inplace=True)
    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): ReLU(inplace=True)
    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (20): ReLU(inplace=True)
    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (22): ReLU(inplace=True)
    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): ReLU(inplace=True)
    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (27): ReLU(inplace=True)
    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (29): ReLU(inplace=True)
    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))
  (classifier): Sequential(
    (0): Linear(in_features=25088, out_features=4096, bias=True)
    (1): ReLU(inplace=True)
    (2): Dropout(p=0.5, inplace=False)
    (3): Linear(in_features=4096, out_features=4096, bias=True)
    (4): ReLU(inplace=True)
    (5): Dropout(p=0.5, inplace=False)
    (6): Linear(in_features=4096, out_features=10, bias=True)
  )
)
{'model': <function VggNet at 0x7f67b8230d08>, 'name': 'vgg16', 'pretrained': True, 'epoch': 5, 'num_class': 10, 'save_path': 'params/vgg.pth', 'input_size': (112, 112), 'batch_size': (8, 1000), 'lr': 0.0001}
[1,     1] train_loss: 0.337  test_accuracy: 0.114
[1,   101] train_loss: 3.154  test_accuracy: 0.314
[1,   201] train_loss: 1.824  test_accuracy: 0.357
[1,   301] train_loss: 1.540  test_accuracy: 0.473
[1,   401] train_loss: 1.500  test_accuracy: 0.544
[1,   501] train_loss: 1.182  test_accuracy: 0.630
[1,   601] train_loss: 1.284  test_accuracy: 0.510
[1,   701] train_loss: 1.336  test_accuracy: 0.567
[1,   801] train_loss: 1.041  test_accuracy: 0.627
[1,   901] train_loss: 1.085  test_accuracy: 0.646
[1,  1001] train_loss: 0.971  test_accuracy: 0.662
[1,  1101] train_loss: 0.921  test_accuracy: 0.730
[1,  1201] train_loss: 0.889  test_accuracy: 0.661
[1,  1301] train_loss: 0.912  test_accuracy: 0.722
[1,  1401] train_loss: 0.864  test_accuracy: 0.734
[1,  1501] train_loss: 0.857  test_accuracy: 0.715
[1,  1601] train_loss: 0.730  test_accuracy: 0.759
[1,  1701] train_loss: 0.716  test_accuracy: 0.711
[1,  1801] train_loss: 0.792  test_accuracy: 0.762
[1,  1901] train_loss: 0.777  test_accuracy: 0.681
[1,  2001] train_loss: 0.826  test_accuracy: 0.763
[1,  2101] train_loss: 0.808  test_accuracy: 0.787
[1,  2201] train_loss: 0.727  test_accuracy: 0.780
[1,  2301] train_loss: 0.654  test_accuracy: 0.770
[1,  2401] train_loss: 0.667  test_accuracy: 0.797
[1,  2501] train_loss: 0.714  test_accuracy: 0.792
[1,  2601] train_loss: 0.695  test_accuracy: 0.740
[1,  2701] train_loss: 0.682  test_accuracy: 0.779
[1,  2801] train_loss: 0.680  test_accuracy: 0.766
[1,  2901] train_loss: 0.745  test_accuracy: 0.820
[1,  3001] train_loss: 0.624  test_accuracy: 0.794
[1,  3101] train_loss: 0.587  test_accuracy: 0.777
[1,  3201] train_loss: 0.606  test_accuracy: 0.804
[1,  3301] train_loss: 0.608  test_accuracy: 0.769
[1,  3401] train_loss: 0.648  test_accuracy: 0.826
[1,  3501] train_loss: 0.471  test_accuracy: 0.818
[1,  3601] train_loss: 0.611  test_accuracy: 0.800
[1,  3701] train_loss: 0.638  test_accuracy: 0.823
[1,  3801] train_loss: 0.568  test_accuracy: 0.820
[1,  3901] train_loss: 0.657  test_accuracy: 0.809
[1,  4001] train_loss: 0.557  test_accuracy: 0.793
[1,  4101] train_loss: 0.587  test_accuracy: 0.812
[1,  4201] train_loss: 0.741  test_accuracy: 0.774
[1,  4301] train_loss: 0.612  test_accuracy: 0.812
[1,  4401] train_loss: 0.614  test_accuracy: 0.753
[1,  4501] train_loss: 0.574  test_accuracy: 0.804
[1,  4601] train_loss: 0.583  test_accuracy: 0.826
[1,  4701] train_loss: 0.504  test_accuracy: 0.823
[1,  4801] train_loss: 0.563  test_accuracy: 0.816
[1,  4901] train_loss: 0.599  test_accuracy: 0.809
[1,  5001] train_loss: 0.534  test_accuracy: 0.833
[1,  5101] train_loss: 0.549  test_accuracy: 0.826
[1,  5201] train_loss: 0.596  test_accuracy: 0.854
[1,  5301] train_loss: 0.552  test_accuracy: 0.843
[1,  5401] train_loss: 0.692  test_accuracy: 0.833
[1,  5501] train_loss: 0.524  test_accuracy: 0.783
[1,  5601] train_loss: 0.605  test_accuracy: 0.795
[1,  5701] train_loss: 0.535  test_accuracy: 0.855
[1,  5801] train_loss: 0.516  test_accuracy: 0.852
[1,  5901] train_loss: 0.510  test_accuracy: 0.831
[1,  6001] train_loss: 0.427  test_accuracy: 0.800
[1,  6101] train_loss: 0.594  test_accuracy: 0.800
[1,  6201] train_loss: 0.569  test_accuracy: 0.833
[2,     1] train_loss: 0.000  test_accuracy: 0.843
[2,   101] train_loss: 0.511  test_accuracy: 0.815
[2,   201] train_loss: 0.467  test_accuracy: 0.844
[2,   301] train_loss: 0.475  test_accuracy: 0.843
[2,   401] train_loss: 0.473  test_accuracy: 0.813
[2,   501] train_loss: 0.488  test_accuracy: 0.856
[2,   601] train_loss: 0.470  test_accuracy: 0.866
[2,   701] train_loss: 0.541  test_accuracy: 0.829
[2,   801] train_loss: 0.443  test_accuracy: 0.803
[2,   901] train_loss: 0.523  test_accuracy: 0.836
[2,  1001] train_loss: 0.469  test_accuracy: 0.842
[2,  1101] train_loss: 0.454  test_accuracy: 0.845
[2,  1201] train_loss: 0.466  test_accuracy: 0.870
[2,  1301] train_loss: 0.493  test_accuracy: 0.835
[2,  1401] train_loss: 0.501  test_accuracy: 0.829
[2,  1501] train_loss: 0.496  test_accuracy: 0.841
[2,  1601] train_loss: 0.450  test_accuracy: 0.843
[2,  1701] train_loss: 0.397  test_accuracy: 0.838
[2,  1801] train_loss: 0.531  test_accuracy: 0.846
[2,  1901] train_loss: 0.397  test_accuracy: 0.852
[2,  2001] train_loss: 0.499  test_accuracy: 0.855
[2,  2101] train_loss: 0.523  test_accuracy: 0.857
[2,  2201] train_loss: 0.485  test_accuracy: 0.853
[2,  2301] train_loss: 0.439  test_accuracy: 0.867
[2,  2401] train_loss: 0.470  test_accuracy: 0.822
[2,  2501] train_loss: 0.479  test_accuracy: 0.824
[2,  2601] train_loss: 0.419  test_accuracy: 0.847
[2,  2701] train_loss: 0.413  test_accuracy: 0.833
[2,  2801] train_loss: 0.439  test_accuracy: 0.844
[2,  2901] train_loss: 0.483  test_accuracy: 0.865
[2,  3001] train_loss: 0.400  test_accuracy: 0.847
[2,  3101] train_loss: 0.393  test_accuracy: 0.857
[2,  3201] train_loss: 0.386  test_accuracy: 0.861
[2,  3301] train_loss: 0.403  test_accuracy: 0.856
[2,  3401] train_loss: 0.434  test_accuracy: 0.871
[2,  3501] train_loss: 0.384  test_accuracy: 0.811
[2,  3601] train_loss: 0.388  test_accuracy: 0.839
[2,  3701] train_loss: 0.432  test_accuracy: 0.861
[2,  3801] train_loss: 0.331  test_accuracy: 0.874
[2,  3901] train_loss: 0.369  test_accuracy: 0.839
[2,  4001] train_loss: 0.412  test_accuracy: 0.844
[2,  4101] train_loss: 0.399  test_accuracy: 0.831
[2,  4201] train_loss: 0.538  test_accuracy: 0.843
[2,  4301] train_loss: 0.414  test_accuracy: 0.848
[2,  4401] train_loss: 0.397  test_accuracy: 0.844
[2,  4501] train_loss: 0.359  test_accuracy: 0.832
[2,  4601] train_loss: 0.438  test_accuracy: 0.856
[2,  4701] train_loss: 0.299  test_accuracy: 0.876
[2,  4801] train_loss: 0.347  test_accuracy: 0.862
[2,  4901] train_loss: 0.437  test_accuracy: 0.836
[2,  5001] train_loss: 0.395  test_accuracy: 0.867
[2,  5101] train_loss: 0.353  test_accuracy: 0.846
[2,  5201] train_loss: 0.449  test_accuracy: 0.853
[2,  5301] train_loss: 0.351  test_accuracy: 0.825
[2,  5401] train_loss: 0.455  test_accuracy: 0.843
[2,  5501] train_loss: 0.401  test_accuracy: 0.864
[2,  5601] train_loss: 0.356  test_accuracy: 0.867
[2,  5701] train_loss: 0.434  test_accuracy: 0.839
[2,  5801] train_loss: 0.336  test_accuracy: 0.858
[2,  5901] train_loss: 0.414  test_accuracy: 0.830
[2,  6001] train_loss: 0.326  test_accuracy: 0.836
[2,  6101] train_loss: 0.347  test_accuracy: 0.860
[2,  6201] train_loss: 0.408  test_accuracy: 0.854
[3,     1] train_loss: 0.000  test_accuracy: 0.879
[3,   101] train_loss: 0.342  test_accuracy: 0.830
[3,   201] train_loss: 0.348  test_accuracy: 0.873
[3,   301] train_loss: 0.310  test_accuracy: 0.863
[3,   401] train_loss: 0.321  test_accuracy: 0.853
[3,   501] train_loss: 0.398  test_accuracy: 0.832
[3,   601] train_loss: 0.340  test_accuracy: 0.873
[3,   701] train_loss: 0.300  test_accuracy: 0.852
[3,   801] train_loss: 0.314  test_accuracy: 0.888
[3,   901] train_loss: 0.321  test_accuracy: 0.849
[3,  1001] train_loss: 0.309  test_accuracy: 0.869
[3,  1101] train_loss: 0.346  test_accuracy: 0.867
[3,  1201] train_loss: 0.351  test_accuracy: 0.860
[3,  1301] train_loss: 0.393  test_accuracy: 0.846
[3,  1401] train_loss: 0.380  test_accuracy: 0.870
[3,  1501] train_loss: 0.270  test_accuracy: 0.879
[3,  1601] train_loss: 0.253  test_accuracy: 0.866
[3,  1701] train_loss: 0.320  test_accuracy: 0.838
[3,  1801] train_loss: 0.396  test_accuracy: 0.857
[3,  1901] train_loss: 0.345  test_accuracy: 0.886
[3,  2001] train_loss: 0.351  test_accuracy: 0.892
[3,  2101] train_loss: 0.432  test_accuracy: 0.866
[3,  2201] train_loss: 0.310  test_accuracy: 0.839
[3,  2301] train_loss: 0.360  test_accuracy: 0.847
[3,  2401] train_loss: 0.305  test_accuracy: 0.838
[3,  2501] train_loss: 0.369  test_accuracy: 0.852
[3,  2601] train_loss: 0.254  test_accuracy: 0.865
[3,  2701] train_loss: 0.319  test_accuracy: 0.814
[3,  2801] train_loss: 0.305  test_accuracy: 0.868
[3,  2901] train_loss: 0.325  test_accuracy: 0.870
[3,  3001] train_loss: 0.258  test_accuracy: 0.876
[3,  3101] train_loss: 0.328  test_accuracy: 0.870
[3,  3201] train_loss: 0.299  test_accuracy: 0.872
[3,  3301] train_loss: 0.275  test_accuracy: 0.878
[3,  3401] train_loss: 0.269  test_accuracy: 0.880
[3,  3501] train_loss: 0.305  test_accuracy: 0.843
[3,  3601] train_loss: 0.238  test_accuracy: 0.868
[3,  3701] train_loss: 0.341  test_accuracy: 0.866
[3,  3801] train_loss: 0.328  test_accuracy: 0.874
[3,  3901] train_loss: 0.387  test_accuracy: 0.864
[3,  4001] train_loss: 0.277  test_accuracy: 0.863
[3,  4101] train_loss: 0.381  test_accuracy: 0.833
[3,  4201] train_loss: 0.349  test_accuracy: 0.888
[3,  4301] train_loss: 0.289  test_accuracy: 0.876
[3,  4401] train_loss: 0.261  test_accuracy: 0.870
[3,  4501] train_loss: 0.225  test_accuracy: 0.878
[3,  4601] train_loss: 0.325  test_accuracy: 0.863
[3,  4701] train_loss: 0.303  test_accuracy: 0.866
[3,  4801] train_loss: 0.397  test_accuracy: 0.838
[3,  4901] train_loss: 0.322  test_accuracy: 0.879
[3,  5001] train_loss: 0.259  test_accuracy: 0.885
[3,  5101] train_loss: 0.262  test_accuracy: 0.876
[3,  5201] train_loss: 0.280  test_accuracy: 0.851
[3,  5301] train_loss: 0.240  test_accuracy: 0.866
[3,  5401] train_loss: 0.316  test_accuracy: 0.868
[3,  5501] train_loss: 0.266  test_accuracy: 0.853
[3,  5601] train_loss: 0.257  test_accuracy: 0.857
[3,  5701] train_loss: 0.344  test_accuracy: 0.833
[3,  5801] train_loss: 0.306  test_accuracy: 0.868
[3,  5901] train_loss: 0.221  test_accuracy: 0.859
[3,  6001] train_loss: 0.322  test_accuracy: 0.860
[3,  6101] train_loss: 0.268  test_accuracy: 0.853
[3,  6201] train_loss: 0.320  test_accuracy: 0.828
[4,     1] train_loss: 0.000  test_accuracy: 0.860
[4,   101] train_loss: 0.289  test_accuracy: 0.862
[4,   201] train_loss: 0.312  test_accuracy: 0.882
[4,   301] train_loss: 0.268  test_accuracy: 0.876
[4,   401] train_loss: 0.179  test_accuracy: 0.873
[4,   501] train_loss: 0.285  test_accuracy: 0.850
[4,   601] train_loss: 0.275  test_accuracy: 0.872
[4,   701] train_loss: 0.293  test_accuracy: 0.881
[4,   801] train_loss: 0.289  test_accuracy: 0.890
[4,   901] train_loss: 0.302  test_accuracy: 0.891
[4,  1001] train_loss: 0.302  test_accuracy: 0.884
[4,  1101] train_loss: 0.239  test_accuracy: 0.883
[4,  1201] train_loss: 0.293  test_accuracy: 0.887
[4,  1301] train_loss: 0.243  test_accuracy: 0.858
[4,  1401] train_loss: 0.316  test_accuracy: 0.871
[4,  1501] train_loss: 0.288  test_accuracy: 0.887
[4,  1601] train_loss: 0.261  test_accuracy: 0.882
[4,  1701] train_loss: 0.257  test_accuracy: 0.868
[4,  1801] train_loss: 0.289  test_accuracy: 0.857
[4,  1901] train_loss: 0.219  test_accuracy: 0.894
[4,  2001] train_loss: 0.224  test_accuracy: 0.883
[4,  2101] train_loss: 0.304  test_accuracy: 0.884
[4,  2201] train_loss: 0.310  test_accuracy: 0.878
[4,  2301] train_loss: 0.224  test_accuracy: 0.891
[4,  2401] train_loss: 0.306  test_accuracy: 0.877
[4,  2501] train_loss: 0.226  test_accuracy: 0.881
[4,  2601] train_loss: 0.269  test_accuracy: 0.878
[4,  2701] train_loss: 0.276  test_accuracy: 0.879
[4,  2801] train_loss: 0.272  test_accuracy: 0.886
[4,  2901] train_loss: 0.254  test_accuracy: 0.863
[4,  3001] train_loss: 0.171  test_accuracy: 0.884
[4,  3101] train_loss: 0.218  test_accuracy: 0.854
[4,  3201] train_loss: 0.261  test_accuracy: 0.876
[4,  3301] train_loss: 0.282  test_accuracy: 0.819
[4,  3401] train_loss: 0.256  test_accuracy: 0.905
[4,  3501] train_loss: 0.214  test_accuracy: 0.881
[4,  3601] train_loss: 0.159  test_accuracy: 0.895
[4,  3701] train_loss: 0.177  test_accuracy: 0.882
[4,  3801] train_loss: 0.248  test_accuracy: 0.887
[4,  3901] train_loss: 0.300  test_accuracy: 0.880
[4,  4001] train_loss: 0.270  test_accuracy: 0.888
[4,  4101] train_loss: 0.197  test_accuracy: 0.860
[4,  4201] train_loss: 0.267  test_accuracy: 0.891
[4,  4301] train_loss: 0.296  test_accuracy: 0.863
[4,  4401] train_loss: 0.199  test_accuracy: 0.869
[4,  4501] train_loss: 0.175  test_accuracy: 0.876
[4,  4601] train_loss: 0.254  test_accuracy: 0.841
[4,  4701] train_loss: 0.199  test_accuracy: 0.884
[4,  4801] train_loss: 0.232  test_accuracy: 0.848
[4,  4901] train_loss: 0.332  test_accuracy: 0.888
[4,  5001] train_loss: 0.217  test_accuracy: 0.875
[4,  5101] train_loss: 0.188  test_accuracy: 0.881
[4,  5201] train_loss: 0.168  test_accuracy: 0.887
[4,  5301] train_loss: 0.179  test_accuracy: 0.897
[4,  5401] train_loss: 0.340  test_accuracy: 0.880
[4,  5501] train_loss: 0.200  test_accuracy: 0.880
[4,  5601] train_loss: 0.261  test_accuracy: 0.874
[4,  5701] train_loss: 0.230  test_accuracy: 0.876
[4,  5801] train_loss: 0.265  test_accuracy: 0.876
[4,  5901] train_loss: 0.279  test_accuracy: 0.867
[4,  6001] train_loss: 0.296  test_accuracy: 0.886
[4,  6101] train_loss: 0.217  test_accuracy: 0.887
[4,  6201] train_loss: 0.322  test_accuracy: 0.842
[5,     1] train_loss: 0.000  test_accuracy: 0.892
[5,   101] train_loss: 0.249  test_accuracy: 0.890
[5,   201] train_loss: 0.177  test_accuracy: 0.902
[5,   301] train_loss: 0.171  test_accuracy: 0.879
[5,   401] train_loss: 0.198  test_accuracy: 0.890
[5,   501] train_loss: 0.283  test_accuracy: 0.859
[5,   601] train_loss: 0.218  test_accuracy: 0.863
[5,   701] train_loss: 0.256  test_accuracy: 0.880
[5,   801] train_loss: 0.198  test_accuracy: 0.911
[5,   901] train_loss: 0.258  test_accuracy: 0.880
[5,  1001] train_loss: 0.300  test_accuracy: 0.876
[5,  1101] train_loss: 0.219  test_accuracy: 0.874
[5,  1201] train_loss: 0.212  test_accuracy: 0.903
[5,  1301] train_loss: 0.277  test_accuracy: 0.891
[5,  1401] train_loss: 0.257  test_accuracy: 0.886
[5,  1501] train_loss: 0.232  test_accuracy: 0.883
[5,  1601] train_loss: 0.180  test_accuracy: 0.876
[5,  1701] train_loss: 0.216  test_accuracy: 0.905
[5,  1801] train_loss: 0.284  test_accuracy: 0.864
[5,  1901] train_loss: 0.232  test_accuracy: 0.897
[5,  2001] train_loss: 0.254  test_accuracy: 0.889
[5,  2101] train_loss: 0.262  test_accuracy: 0.862
[5,  2201] train_loss: 0.284  test_accuracy: 0.864
[5,  2301] train_loss: 0.245  test_accuracy: 0.876
[5,  2401] train_loss: 0.270  test_accuracy: 0.876
[5,  2501] train_loss: 0.201  test_accuracy: 0.900
[5,  2601] train_loss: 0.209  test_accuracy: 0.894
[5,  2701] train_loss: 0.170  test_accuracy: 0.880
[5,  2801] train_loss: 0.191  test_accuracy: 0.867
[5,  2901] train_loss: 0.207  test_accuracy: 0.885
[5,  3001] train_loss: 0.177  test_accuracy: 0.888
[5,  3101] train_loss: 0.202  test_accuracy: 0.874
[5,  3201] train_loss: 0.196  test_accuracy: 0.899
[5,  3301] train_loss: 0.190  test_accuracy: 0.890
[5,  3401] train_loss: 0.197  test_accuracy: 0.870
[5,  3501] train_loss: 0.196  test_accuracy: 0.858
[5,  3601] train_loss: 0.181  test_accuracy: 0.882
[5,  3701] train_loss: 0.157  test_accuracy: 0.881
[5,  3801] train_loss: 0.147  test_accuracy: 0.895
[5,  3901] train_loss: 0.265  test_accuracy: 0.847
[5,  4001] train_loss: 0.208  test_accuracy: 0.885
[5,  4101] train_loss: 0.230  test_accuracy: 0.886
[5,  4201] train_loss: 0.222  test_accuracy: 0.880
[5,  4301] train_loss: 0.206  test_accuracy: 0.875
[5,  4401] train_loss: 0.201  test_accuracy: 0.885
[5,  4501] train_loss: 0.131  test_accuracy: 0.877
[5,  4601] train_loss: 0.241  test_accuracy: 0.850
[5,  4701] train_loss: 0.248  test_accuracy: 0.884
[5,  4801] train_loss: 0.312  test_accuracy: 0.878
[5,  4901] train_loss: 0.213  test_accuracy: 0.875
[5,  5001] train_loss: 0.206  test_accuracy: 0.892
[5,  5101] train_loss: 0.123  test_accuracy: 0.889
[5,  5201] train_loss: 0.219  test_accuracy: 0.894
[5,  5301] train_loss: 0.167  test_accuracy: 0.896
[5,  5401] train_loss: 0.233  test_accuracy: 0.864
[5,  5501] train_loss: 0.165  test_accuracy: 0.886
[5,  5601] train_loss: 0.157  test_accuracy: 0.868
[5,  5701] train_loss: 0.288  test_accuracy: 0.863
[5,  5801] train_loss: 0.249  test_accuracy: 0.871
[5,  5901] train_loss: 0.169  test_accuracy: 0.884
[5,  6001] train_loss: 0.260  test_accuracy: 0.884
[5,  6101] train_loss: 0.204  test_accuracy: 0.863
[5,  6201] train_loss: 0.228  test_accuracy: 0.864
Finished Training
