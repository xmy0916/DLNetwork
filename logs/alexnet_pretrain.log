nohup: ignoring input
AlexNet(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))
    (1): ReLU(inplace=True)
    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (4): ReLU(inplace=True)
    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace=True)
    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (9): ReLU(inplace=True)
    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace=True)
    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))
  (classifier): Sequential(
    (0): Dropout(p=0.5, inplace=False)
    (1): Linear(in_features=9216, out_features=4096, bias=True)
    (2): ReLU(inplace=True)
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=4096, out_features=4096, bias=True)
    (5): ReLU(inplace=True)
    (6): Linear(in_features=4096, out_features=10, bias=True)
  )
)
{'model': <function AlexNet_pretrain at 0x7f687c14c268>, 'epoch': 5, 'num_class': 10, 'save_path': 'params/alexnet_pretrain.pth', 'input_size': (224, 224), 'batch_size': (8, 1000), 'lr': 0.0001}
[1,     1] train_loss: 0.182  test_accuracy: 0.088
[1,   101] train_loss: 3.599  test_accuracy: 0.285
[1,   201] train_loss: 1.989  test_accuracy: 0.327
[1,   301] train_loss: 2.032  test_accuracy: 0.325
[1,   401] train_loss: 1.916  test_accuracy: 0.354
[1,   501] train_loss: 1.829  test_accuracy: 0.397
[1,   601] train_loss: 1.718  test_accuracy: 0.411
[1,   701] train_loss: 1.739  test_accuracy: 0.430
[1,   801] train_loss: 1.614  test_accuracy: 0.474
[1,   901] train_loss: 1.504  test_accuracy: 0.471
[1,  1001] train_loss: 1.511  test_accuracy: 0.496
[1,  1101] train_loss: 1.353  test_accuracy: 0.517
[1,  1201] train_loss: 1.320  test_accuracy: 0.545
[1,  1301] train_loss: 1.377  test_accuracy: 0.571
[1,  1401] train_loss: 1.341  test_accuracy: 0.549
[1,  1501] train_loss: 1.230  test_accuracy: 0.555
[1,  1601] train_loss: 1.260  test_accuracy: 0.569
[1,  1701] train_loss: 1.189  test_accuracy: 0.606
[1,  1801] train_loss: 1.186  test_accuracy: 0.613
[1,  1901] train_loss: 1.131  test_accuracy: 0.622
[1,  2001] train_loss: 1.217  test_accuracy: 0.583
[1,  2101] train_loss: 1.149  test_accuracy: 0.578
[1,  2201] train_loss: 1.134  test_accuracy: 0.635
[1,  2301] train_loss: 1.125  test_accuracy: 0.637
[1,  2401] train_loss: 1.026  test_accuracy: 0.644
[1,  2501] train_loss: 1.000  test_accuracy: 0.636
[1,  2601] train_loss: 1.101  test_accuracy: 0.655
[1,  2701] train_loss: 1.001  test_accuracy: 0.673
[1,  2801] train_loss: 0.966  test_accuracy: 0.667
[1,  2901] train_loss: 1.048  test_accuracy: 0.678
[1,  3001] train_loss: 0.975  test_accuracy: 0.676
[1,  3101] train_loss: 0.852  test_accuracy: 0.658
[1,  3201] train_loss: 0.964  test_accuracy: 0.652
[1,  3301] train_loss: 0.894  test_accuracy: 0.706
[1,  3401] train_loss: 0.982  test_accuracy: 0.709
[1,  3501] train_loss: 0.884  test_accuracy: 0.673
[1,  3601] train_loss: 0.937  test_accuracy: 0.658
[1,  3701] train_loss: 0.872  test_accuracy: 0.725
[1,  3801] train_loss: 0.804  test_accuracy: 0.734
[1,  3901] train_loss: 0.828  test_accuracy: 0.702
[1,  4001] train_loss: 0.871  test_accuracy: 0.699
[1,  4101] train_loss: 0.886  test_accuracy: 0.732
[1,  4201] train_loss: 0.939  test_accuracy: 0.732
[1,  4301] train_loss: 0.872  test_accuracy: 0.738
[1,  4401] train_loss: 0.835  test_accuracy: 0.714
[1,  4501] train_loss: 0.804  test_accuracy: 0.683
[1,  4601] train_loss: 0.783  test_accuracy: 0.678
[1,  4701] train_loss: 0.830  test_accuracy: 0.737
[1,  4801] train_loss: 0.777  test_accuracy: 0.711
[1,  4901] train_loss: 0.764  test_accuracy: 0.732
[1,  5001] train_loss: 0.815  test_accuracy: 0.738
[1,  5101] train_loss: 0.803  test_accuracy: 0.733
[1,  5201] train_loss: 0.780  test_accuracy: 0.713
[1,  5301] train_loss: 0.722  test_accuracy: 0.729
[1,  5401] train_loss: 0.785  test_accuracy: 0.755
[1,  5501] train_loss: 0.750  test_accuracy: 0.758
[1,  5601] train_loss: 0.752  test_accuracy: 0.756
[1,  5701] train_loss: 0.646  test_accuracy: 0.715
[1,  5801] train_loss: 0.752  test_accuracy: 0.749
[1,  5901] train_loss: 0.697  test_accuracy: 0.766
[1,  6001] train_loss: 0.668  test_accuracy: 0.746
[1,  6101] train_loss: 0.714  test_accuracy: 0.742
[1,  6201] train_loss: 0.687  test_accuracy: 0.741
[2,     1] train_loss: 0.002  test_accuracy: 0.753
[2,   101] train_loss: 0.676  test_accuracy: 0.770
[2,   201] train_loss: 0.648  test_accuracy: 0.754
[2,   301] train_loss: 0.635  test_accuracy: 0.730
[2,   401] train_loss: 0.678  test_accuracy: 0.739
[2,   501] train_loss: 0.670  test_accuracy: 0.765
[2,   601] train_loss: 0.684  test_accuracy: 0.745
[2,   701] train_loss: 0.771  test_accuracy: 0.768
[2,   801] train_loss: 0.681  test_accuracy: 0.784
[2,   901] train_loss: 0.700  test_accuracy: 0.726
[2,  1001] train_loss: 0.761  test_accuracy: 0.756
[2,  1101] train_loss: 0.646  test_accuracy: 0.761
[2,  1201] train_loss: 0.674  test_accuracy: 0.774
[2,  1301] train_loss: 0.681  test_accuracy: 0.772
[2,  1401] train_loss: 0.696  test_accuracy: 0.757
[2,  1501] train_loss: 0.597  test_accuracy: 0.769
[2,  1601] train_loss: 0.618  test_accuracy: 0.770
[2,  1701] train_loss: 0.569  test_accuracy: 0.785
[2,  1801] train_loss: 0.688  test_accuracy: 0.783
[2,  1901] train_loss: 0.583  test_accuracy: 0.789
[2,  2001] train_loss: 0.738  test_accuracy: 0.784
[2,  2101] train_loss: 0.623  test_accuracy: 0.780
[2,  2201] train_loss: 0.679  test_accuracy: 0.787
[2,  2301] train_loss: 0.607  test_accuracy: 0.773
[2,  2401] train_loss: 0.541  test_accuracy: 0.756
[2,  2501] train_loss: 0.594  test_accuracy: 0.798
[2,  2601] train_loss: 0.548  test_accuracy: 0.782
[2,  2701] train_loss: 0.578  test_accuracy: 0.784
[2,  2801] train_loss: 0.624  test_accuracy: 0.767
[2,  2901] train_loss: 0.688  test_accuracy: 0.758
[2,  3001] train_loss: 0.543  test_accuracy: 0.768
[2,  3101] train_loss: 0.583  test_accuracy: 0.747
[2,  3201] train_loss: 0.614  test_accuracy: 0.811
[2,  3301] train_loss: 0.510  test_accuracy: 0.814
[2,  3401] train_loss: 0.570  test_accuracy: 0.795
[2,  3501] train_loss: 0.609  test_accuracy: 0.763
[2,  3601] train_loss: 0.618  test_accuracy: 0.797
[2,  3701] train_loss: 0.521  test_accuracy: 0.801
[2,  3801] train_loss: 0.533  test_accuracy: 0.802
[2,  3901] train_loss: 0.645  test_accuracy: 0.786
[2,  4001] train_loss: 0.549  test_accuracy: 0.766
[2,  4101] train_loss: 0.571  test_accuracy: 0.776
[2,  4201] train_loss: 0.647  test_accuracy: 0.802
[2,  4301] train_loss: 0.597  test_accuracy: 0.792
[2,  4401] train_loss: 0.557  test_accuracy: 0.808
[2,  4501] train_loss: 0.583  test_accuracy: 0.791
[2,  4601] train_loss: 0.557  test_accuracy: 0.767
[2,  4701] train_loss: 0.601  test_accuracy: 0.804
[2,  4801] train_loss: 0.608  test_accuracy: 0.817
[2,  4901] train_loss: 0.524  test_accuracy: 0.823
[2,  5001] train_loss: 0.534  test_accuracy: 0.782
[2,  5101] train_loss: 0.543  test_accuracy: 0.792
[2,  5201] train_loss: 0.490  test_accuracy: 0.806
[2,  5301] train_loss: 0.485  test_accuracy: 0.778
[2,  5401] train_loss: 0.569  test_accuracy: 0.803
[2,  5501] train_loss: 0.515  test_accuracy: 0.796
[2,  5601] train_loss: 0.542  test_accuracy: 0.792
[2,  5701] train_loss: 0.498  test_accuracy: 0.757
[2,  5801] train_loss: 0.478  test_accuracy: 0.787
[2,  5901] train_loss: 0.524  test_accuracy: 0.746
[2,  6001] train_loss: 0.500  test_accuracy: 0.789
[2,  6101] train_loss: 0.458  test_accuracy: 0.786
[2,  6201] train_loss: 0.534  test_accuracy: 0.780
[3,     1] train_loss: 0.002  test_accuracy: 0.805
[3,   101] train_loss: 0.509  test_accuracy: 0.793
[3,   201] train_loss: 0.493  test_accuracy: 0.792
[3,   301] train_loss: 0.448  test_accuracy: 0.819
[3,   401] train_loss: 0.454  test_accuracy: 0.804
[3,   501] train_loss: 0.437  test_accuracy: 0.803
[3,   601] train_loss: 0.468  test_accuracy: 0.817
[3,   701] train_loss: 0.567  test_accuracy: 0.800
[3,   801] train_loss: 0.473  test_accuracy: 0.820
[3,   901] train_loss: 0.525  test_accuracy: 0.811
[3,  1001] train_loss: 0.455  test_accuracy: 0.815
[3,  1101] train_loss: 0.498  test_accuracy: 0.785
[3,  1201] train_loss: 0.474  test_accuracy: 0.819
[3,  1301] train_loss: 0.488  test_accuracy: 0.776
[3,  1401] train_loss: 0.527  test_accuracy: 0.810
[3,  1501] train_loss: 0.458  test_accuracy: 0.808
[3,  1601] train_loss: 0.423  test_accuracy: 0.802
[3,  1701] train_loss: 0.446  test_accuracy: 0.806
[3,  1801] train_loss: 0.504  test_accuracy: 0.815
[3,  1901] train_loss: 0.402  test_accuracy: 0.803
[3,  2001] train_loss: 0.540  test_accuracy: 0.789
[3,  2101] train_loss: 0.512  test_accuracy: 0.806
[3,  2201] train_loss: 0.452  test_accuracy: 0.801
[3,  2301] train_loss: 0.488  test_accuracy: 0.802
[3,  2401] train_loss: 0.434  test_accuracy: 0.820
[3,  2501] train_loss: 0.478  test_accuracy: 0.807
[3,  2601] train_loss: 0.439  test_accuracy: 0.808
[3,  2701] train_loss: 0.457  test_accuracy: 0.800
[3,  2801] train_loss: 0.478  test_accuracy: 0.808
[3,  2901] train_loss: 0.505  test_accuracy: 0.792
[3,  3001] train_loss: 0.397  test_accuracy: 0.807
[3,  3101] train_loss: 0.485  test_accuracy: 0.800
[3,  3201] train_loss: 0.421  test_accuracy: 0.799
[3,  3301] train_loss: 0.469  test_accuracy: 0.821
[3,  3401] train_loss: 0.468  test_accuracy: 0.824
[3,  3501] train_loss: 0.441  test_accuracy: 0.779
[3,  3601] train_loss: 0.403  test_accuracy: 0.806
[3,  3701] train_loss: 0.360  test_accuracy: 0.813
[3,  3801] train_loss: 0.360  test_accuracy: 0.800
[3,  3901] train_loss: 0.480  test_accuracy: 0.826
[3,  4001] train_loss: 0.417  test_accuracy: 0.817
[3,  4101] train_loss: 0.491  test_accuracy: 0.793
[3,  4201] train_loss: 0.519  test_accuracy: 0.804
[3,  4301] train_loss: 0.438  test_accuracy: 0.804
[3,  4401] train_loss: 0.416  test_accuracy: 0.820
[3,  4501] train_loss: 0.382  test_accuracy: 0.819
[3,  4601] train_loss: 0.448  test_accuracy: 0.814
[3,  4701] train_loss: 0.461  test_accuracy: 0.796
[3,  4801] train_loss: 0.502  test_accuracy: 0.815
[3,  4901] train_loss: 0.390  test_accuracy: 0.821
[3,  5001] train_loss: 0.456  test_accuracy: 0.821
[3,  5101] train_loss: 0.445  test_accuracy: 0.815
[3,  5201] train_loss: 0.398  test_accuracy: 0.817
[3,  5301] train_loss: 0.370  test_accuracy: 0.813
[3,  5401] train_loss: 0.354  test_accuracy: 0.823
[3,  5501] train_loss: 0.370  test_accuracy: 0.824
[3,  5601] train_loss: 0.406  test_accuracy: 0.784
[3,  5701] train_loss: 0.391  test_accuracy: 0.803
[3,  5801] train_loss: 0.414  test_accuracy: 0.830
[3,  5901] train_loss: 0.373  test_accuracy: 0.787
[3,  6001] train_loss: 0.387  test_accuracy: 0.819
[3,  6101] train_loss: 0.421  test_accuracy: 0.821
[3,  6201] train_loss: 0.407  test_accuracy: 0.817
[4,     1] train_loss: 0.003  test_accuracy: 0.832
[4,   101] train_loss: 0.376  test_accuracy: 0.814
[4,   201] train_loss: 0.421  test_accuracy: 0.821
[4,   301] train_loss: 0.360  test_accuracy: 0.814
[4,   401] train_loss: 0.338  test_accuracy: 0.836
[4,   501] train_loss: 0.359  test_accuracy: 0.819
[4,   601] train_loss: 0.379  test_accuracy: 0.808
[4,   701] train_loss: 0.437  test_accuracy: 0.806
[4,   801] train_loss: 0.396  test_accuracy: 0.832
[4,   901] train_loss: 0.410  test_accuracy: 0.788
[4,  1001] train_loss: 0.369  test_accuracy: 0.827
[4,  1101] train_loss: 0.391  test_accuracy: 0.833
[4,  1201] train_loss: 0.387  test_accuracy: 0.827
[4,  1301] train_loss: 0.345  test_accuracy: 0.811
[4,  1401] train_loss: 0.419  test_accuracy: 0.828
[4,  1501] train_loss: 0.372  test_accuracy: 0.835
[4,  1601] train_loss: 0.346  test_accuracy: 0.814
[4,  1701] train_loss: 0.335  test_accuracy: 0.822
[4,  1801] train_loss: 0.444  test_accuracy: 0.834
[4,  1901] train_loss: 0.325  test_accuracy: 0.830
[4,  2001] train_loss: 0.465  test_accuracy: 0.834
[4,  2101] train_loss: 0.375  test_accuracy: 0.836
[4,  2201] train_loss: 0.437  test_accuracy: 0.829
[4,  2301] train_loss: 0.382  test_accuracy: 0.833
[4,  2401] train_loss: 0.385  test_accuracy: 0.856
[4,  2501] train_loss: 0.330  test_accuracy: 0.836
[4,  2601] train_loss: 0.364  test_accuracy: 0.832
[4,  2701] train_loss: 0.394  test_accuracy: 0.840
[4,  2801] train_loss: 0.344  test_accuracy: 0.832
[4,  2901] train_loss: 0.459  test_accuracy: 0.818
[4,  3001] train_loss: 0.307  test_accuracy: 0.841
[4,  3101] train_loss: 0.369  test_accuracy: 0.784
[4,  3201] train_loss: 0.354  test_accuracy: 0.826
[4,  3301] train_loss: 0.339  test_accuracy: 0.827
[4,  3401] train_loss: 0.446  test_accuracy: 0.826
[4,  3501] train_loss: 0.392  test_accuracy: 0.817
[4,  3601] train_loss: 0.376  test_accuracy: 0.825
[4,  3701] train_loss: 0.294  test_accuracy: 0.834
[4,  3801] train_loss: 0.305  test_accuracy: 0.842
[4,  3901] train_loss: 0.387  test_accuracy: 0.832
[4,  4001] train_loss: 0.358  test_accuracy: 0.813
[4,  4101] train_loss: 0.305  test_accuracy: 0.824
[4,  4201] train_loss: 0.403  test_accuracy: 0.815
[4,  4301] train_loss: 0.403  test_accuracy: 0.813
[4,  4401] train_loss: 0.372  test_accuracy: 0.840
[4,  4501] train_loss: 0.313  test_accuracy: 0.821
[4,  4601] train_loss: 0.360  test_accuracy: 0.805
[4,  4701] train_loss: 0.336  test_accuracy: 0.827
[4,  4801] train_loss: 0.414  test_accuracy: 0.816
[4,  4901] train_loss: 0.390  test_accuracy: 0.822
[4,  5001] train_loss: 0.395  test_accuracy: 0.810
[4,  5101] train_loss: 0.321  test_accuracy: 0.823
[4,  5201] train_loss: 0.306  test_accuracy: 0.815
[4,  5301] train_loss: 0.291  test_accuracy: 0.829
[4,  5401] train_loss: 0.343  test_accuracy: 0.817
[4,  5501] train_loss: 0.334  test_accuracy: 0.835
[4,  5601] train_loss: 0.361  test_accuracy: 0.815
[4,  5701] train_loss: 0.343  test_accuracy: 0.822
[4,  5801] train_loss: 0.330  test_accuracy: 0.826
[4,  5901] train_loss: 0.324  test_accuracy: 0.822
[4,  6001] train_loss: 0.342  test_accuracy: 0.821
[4,  6101] train_loss: 0.318  test_accuracy: 0.836
[4,  6201] train_loss: 0.281  test_accuracy: 0.836
[5,     1] train_loss: 0.002  test_accuracy: 0.826
[5,   101] train_loss: 0.335  test_accuracy: 0.824
[5,   201] train_loss: 0.330  test_accuracy: 0.839
[5,   301] train_loss: 0.291  test_accuracy: 0.843
[5,   401] train_loss: 0.286  test_accuracy: 0.829
[5,   501] train_loss: 0.324  test_accuracy: 0.812
[5,   601] train_loss: 0.334  test_accuracy: 0.844
[5,   701] train_loss: 0.307  test_accuracy: 0.857
[5,   801] train_loss: 0.288  test_accuracy: 0.831
[5,   901] train_loss: 0.293  test_accuracy: 0.812
[5,  1001] train_loss: 0.325  test_accuracy: 0.816
[5,  1101] train_loss: 0.279  test_accuracy: 0.848
[5,  1201] train_loss: 0.404  test_accuracy: 0.823
[5,  1301] train_loss: 0.295  test_accuracy: 0.821
[5,  1401] train_loss: 0.382  test_accuracy: 0.844
[5,  1501] train_loss: 0.296  test_accuracy: 0.840
[5,  1601] train_loss: 0.316  test_accuracy: 0.834
[5,  1701] train_loss: 0.276  test_accuracy: 0.828
[5,  1801] train_loss: 0.341  test_accuracy: 0.833
[5,  1901] train_loss: 0.260  test_accuracy: 0.835
[5,  2001] train_loss: 0.348  test_accuracy: 0.819
[5,  2101] train_loss: 0.313  test_accuracy: 0.837
[5,  2201] train_loss: 0.321  test_accuracy: 0.860
[5,  2301] train_loss: 0.338  test_accuracy: 0.829
[5,  2401] train_loss: 0.281  test_accuracy: 0.809
[5,  2501] train_loss: 0.384  test_accuracy: 0.839
[5,  2601] train_loss: 0.280  test_accuracy: 0.836
[5,  2701] train_loss: 0.318  test_accuracy: 0.850
[5,  2801] train_loss: 0.375  test_accuracy: 0.842
[5,  2901] train_loss: 0.346  test_accuracy: 0.829
[5,  3001] train_loss: 0.221  test_accuracy: 0.835
[5,  3101] train_loss: 0.383  test_accuracy: 0.816
[5,  3201] train_loss: 0.323  test_accuracy: 0.847
[5,  3301] train_loss: 0.268  test_accuracy: 0.852
[5,  3401] train_loss: 0.321  test_accuracy: 0.838
[5,  3501] train_loss: 0.299  test_accuracy: 0.811
[5,  3601] train_loss: 0.292  test_accuracy: 0.819
[5,  3701] train_loss: 0.288  test_accuracy: 0.831
[5,  3801] train_loss: 0.286  test_accuracy: 0.817
[5,  3901] train_loss: 0.367  test_accuracy: 0.839
[5,  4001] train_loss: 0.313  test_accuracy: 0.830
[5,  4101] train_loss: 0.335  test_accuracy: 0.826
[5,  4201] train_loss: 0.343  test_accuracy: 0.858
[5,  4301] train_loss: 0.317  test_accuracy: 0.814
[5,  4401] train_loss: 0.316  test_accuracy: 0.792
[5,  4501] train_loss: 0.314  test_accuracy: 0.814
[5,  4601] train_loss: 0.313  test_accuracy: 0.822
[5,  4701] train_loss: 0.366  test_accuracy: 0.814
[5,  4801] train_loss: 0.299  test_accuracy: 0.846
[5,  4901] train_loss: 0.257  test_accuracy: 0.847
[5,  5001] train_loss: 0.318  test_accuracy: 0.843
[5,  5101] train_loss: 0.355  test_accuracy: 0.824
[5,  5201] train_loss: 0.290  test_accuracy: 0.847
[5,  5301] train_loss: 0.252  test_accuracy: 0.854
[5,  5401] train_loss: 0.303  test_accuracy: 0.807
[5,  5501] train_loss: 0.313  test_accuracy: 0.833
[5,  5601] train_loss: 0.271  test_accuracy: 0.834
[5,  5701] train_loss: 0.237  test_accuracy: 0.816
[5,  5801] train_loss: 0.235  test_accuracy: 0.837
[5,  5901] train_loss: 0.288  test_accuracy: 0.831
[5,  6001] train_loss: 0.329  test_accuracy: 0.847
[5,  6101] train_loss: 0.247  test_accuracy: 0.852
[5,  6201] train_loss: 0.293  test_accuracy: 0.810
Finished Training
