nohup: ignoring input
AlexNet(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))
    (1): ReLU(inplace=True)
    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))
    (4): ReLU(inplace=True)
    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (7): ReLU(inplace=True)
    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (9): ReLU(inplace=True)
    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace=True)
    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))
  (classifier): Sequential(
    (0): Dropout(p=0.5, inplace=False)
    (1): Linear(in_features=9216, out_features=4096, bias=True)
    (2): ReLU(inplace=True)
    (3): Dropout(p=0.5, inplace=False)
    (4): Linear(in_features=4096, out_features=4096, bias=True)
    (5): ReLU(inplace=True)
    (6): Linear(in_features=4096, out_features=10, bias=True)
  )
)
{'model': <class 'model.AlexNet.AlexNet'>, 'epoch': 5, 'num_class': 10, 'save_path': 'params/alexnet.pth', 'input_size': (224, 224), 'batch_size': (8, 1000), 'lr': 0.0001}
[1,     1] train_loss: 0.023  test_accuracy: 0.110
[1,   101] train_loss: 2.277  test_accuracy: 0.225
[1,   201] train_loss: 2.145  test_accuracy: 0.241
[1,   301] train_loss: 2.116  test_accuracy: 0.243
[1,   401] train_loss: 2.021  test_accuracy: 0.239
[1,   501] train_loss: 1.910  test_accuracy: 0.255
[1,   601] train_loss: 1.815  test_accuracy: 0.324
[1,   701] train_loss: 1.842  test_accuracy: 0.323
[1,   801] train_loss: 1.735  test_accuracy: 0.359
[1,   901] train_loss: 1.697  test_accuracy: 0.342
[1,  1001] train_loss: 1.737  test_accuracy: 0.367
[1,  1101] train_loss: 1.619  test_accuracy: 0.393
[1,  1201] train_loss: 1.656  test_accuracy: 0.388
[1,  1301] train_loss: 1.635  test_accuracy: 0.415
[1,  1401] train_loss: 1.644  test_accuracy: 0.421
[1,  1501] train_loss: 1.568  test_accuracy: 0.403
[1,  1601] train_loss: 1.534  test_accuracy: 0.479
[1,  1701] train_loss: 1.537  test_accuracy: 0.483
[1,  1801] train_loss: 1.523  test_accuracy: 0.436
[1,  1901] train_loss: 1.538  test_accuracy: 0.458
[1,  2001] train_loss: 1.538  test_accuracy: 0.445
[1,  2101] train_loss: 1.443  test_accuracy: 0.449
[1,  2201] train_loss: 1.395  test_accuracy: 0.442
[1,  2301] train_loss: 1.437  test_accuracy: 0.518
[1,  2401] train_loss: 1.405  test_accuracy: 0.511
[1,  2501] train_loss: 1.412  test_accuracy: 0.491
[1,  2601] train_loss: 1.401  test_accuracy: 0.519
[1,  2701] train_loss: 1.383  test_accuracy: 0.488
[1,  2801] train_loss: 1.325  test_accuracy: 0.484
[1,  2901] train_loss: 1.391  test_accuracy: 0.543
[1,  3001] train_loss: 1.267  test_accuracy: 0.505
[1,  3101] train_loss: 1.298  test_accuracy: 0.488
[1,  3201] train_loss: 1.284  test_accuracy: 0.544
[1,  3301] train_loss: 1.256  test_accuracy: 0.545
[1,  3401] train_loss: 1.299  test_accuracy: 0.552
[1,  3501] train_loss: 1.281  test_accuracy: 0.548
[1,  3601] train_loss: 1.282  test_accuracy: 0.564
[1,  3701] train_loss: 1.238  test_accuracy: 0.555
[1,  3801] train_loss: 1.220  test_accuracy: 0.590
[1,  3901] train_loss: 1.247  test_accuracy: 0.552
[1,  4001] train_loss: 1.252  test_accuracy: 0.567
[1,  4101] train_loss: 1.267  test_accuracy: 0.590
[1,  4201] train_loss: 1.302  test_accuracy: 0.572
[1,  4301] train_loss: 1.198  test_accuracy: 0.554
[1,  4401] train_loss: 1.210  test_accuracy: 0.574
[1,  4501] train_loss: 1.188  test_accuracy: 0.587
[1,  4601] train_loss: 1.149  test_accuracy: 0.524
[1,  4701] train_loss: 1.212  test_accuracy: 0.612
[1,  4801] train_loss: 1.177  test_accuracy: 0.585
[1,  4901] train_loss: 1.111  test_accuracy: 0.598
[1,  5001] train_loss: 1.164  test_accuracy: 0.624
[1,  5101] train_loss: 1.147  test_accuracy: 0.620
[1,  5201] train_loss: 1.182  test_accuracy: 0.607
[1,  5301] train_loss: 1.076  test_accuracy: 0.609
[1,  5401] train_loss: 1.143  test_accuracy: 0.621
[1,  5501] train_loss: 1.143  test_accuracy: 0.588
[1,  5601] train_loss: 1.154  test_accuracy: 0.609
[1,  5701] train_loss: 1.004  test_accuracy: 0.630
[1,  5801] train_loss: 1.039  test_accuracy: 0.615
[1,  5901] train_loss: 1.135  test_accuracy: 0.610
[1,  6001] train_loss: 1.111  test_accuracy: 0.640
[1,  6101] train_loss: 1.054  test_accuracy: 0.615
[1,  6201] train_loss: 1.060  test_accuracy: 0.627
[2,     1] train_loss: 0.010  test_accuracy: 0.631
[2,   101] train_loss: 1.009  test_accuracy: 0.623
[2,   201] train_loss: 1.075  test_accuracy: 0.630
[2,   301] train_loss: 1.034  test_accuracy: 0.641
[2,   401] train_loss: 1.033  test_accuracy: 0.631
[2,   501] train_loss: 1.031  test_accuracy: 0.645
[2,   601] train_loss: 1.044  test_accuracy: 0.651
[2,   701] train_loss: 1.083  test_accuracy: 0.665
[2,   801] train_loss: 1.016  test_accuracy: 0.626
[2,   901] train_loss: 1.007  test_accuracy: 0.629
[2,  1001] train_loss: 0.975  test_accuracy: 0.653
[2,  1101] train_loss: 0.924  test_accuracy: 0.645
[2,  1201] train_loss: 0.983  test_accuracy: 0.639
[2,  1301] train_loss: 0.967  test_accuracy: 0.658
[2,  1401] train_loss: 1.005  test_accuracy: 0.669
[2,  1501] train_loss: 0.965  test_accuracy: 0.640
[2,  1601] train_loss: 1.028  test_accuracy: 0.664
[2,  1701] train_loss: 0.959  test_accuracy: 0.662
[2,  1801] train_loss: 1.034  test_accuracy: 0.665
[2,  1901] train_loss: 0.970  test_accuracy: 0.682
[2,  2001] train_loss: 1.026  test_accuracy: 0.640
[2,  2101] train_loss: 0.964  test_accuracy: 0.677
[2,  2201] train_loss: 0.919  test_accuracy: 0.671
[2,  2301] train_loss: 0.963  test_accuracy: 0.649
[2,  2401] train_loss: 0.957  test_accuracy: 0.680
[2,  2501] train_loss: 0.975  test_accuracy: 0.670
[2,  2601] train_loss: 0.928  test_accuracy: 0.688
[2,  2701] train_loss: 0.883  test_accuracy: 0.679
[2,  2801] train_loss: 0.947  test_accuracy: 0.664
[2,  2901] train_loss: 0.950  test_accuracy: 0.686
[2,  3001] train_loss: 0.835  test_accuracy: 0.711
[2,  3101] train_loss: 0.858  test_accuracy: 0.700
[2,  3201] train_loss: 0.918  test_accuracy: 0.685
[2,  3301] train_loss: 0.830  test_accuracy: 0.683
[2,  3401] train_loss: 0.927  test_accuracy: 0.698
[2,  3501] train_loss: 0.811  test_accuracy: 0.714
[2,  3601] train_loss: 0.881  test_accuracy: 0.699
[2,  3701] train_loss: 0.836  test_accuracy: 0.708
[2,  3801] train_loss: 0.817  test_accuracy: 0.722
[2,  3901] train_loss: 0.897  test_accuracy: 0.694
[2,  4001] train_loss: 0.829  test_accuracy: 0.703
[2,  4101] train_loss: 0.886  test_accuracy: 0.721
[2,  4201] train_loss: 0.923  test_accuracy: 0.693
[2,  4301] train_loss: 0.874  test_accuracy: 0.697
[2,  4401] train_loss: 0.905  test_accuracy: 0.675
[2,  4501] train_loss: 0.843  test_accuracy: 0.700
[2,  4601] train_loss: 0.806  test_accuracy: 0.673
[2,  4701] train_loss: 0.877  test_accuracy: 0.695
[2,  4801] train_loss: 0.873  test_accuracy: 0.661
[2,  4901] train_loss: 0.774  test_accuracy: 0.699
[2,  5001] train_loss: 0.831  test_accuracy: 0.713
[2,  5101] train_loss: 0.854  test_accuracy: 0.702
[2,  5201] train_loss: 0.847  test_accuracy: 0.685
[2,  5301] train_loss: 0.777  test_accuracy: 0.701
[2,  5401] train_loss: 0.851  test_accuracy: 0.711
[2,  5501] train_loss: 0.844  test_accuracy: 0.693
[2,  5601] train_loss: 0.781  test_accuracy: 0.730
[2,  5701] train_loss: 0.754  test_accuracy: 0.709
[2,  5801] train_loss: 0.756  test_accuracy: 0.729
[2,  5901] train_loss: 0.771  test_accuracy: 0.709
[2,  6001] train_loss: 0.825  test_accuracy: 0.715
[2,  6101] train_loss: 0.800  test_accuracy: 0.716
[2,  6201] train_loss: 0.761  test_accuracy: 0.721
[3,     1] train_loss: 0.004  test_accuracy: 0.719
[3,   101] train_loss: 0.749  test_accuracy: 0.722
[3,   201] train_loss: 0.791  test_accuracy: 0.710
[3,   301] train_loss: 0.771  test_accuracy: 0.729
[3,   401] train_loss: 0.730  test_accuracy: 0.718
[3,   501] train_loss: 0.763  test_accuracy: 0.714
[3,   601] train_loss: 0.751  test_accuracy: 0.719
[3,   701] train_loss: 0.861  test_accuracy: 0.711
[3,   801] train_loss: 0.722  test_accuracy: 0.700
[3,   901] train_loss: 0.733  test_accuracy: 0.725
[3,  1001] train_loss: 0.679  test_accuracy: 0.737
[3,  1101] train_loss: 0.707  test_accuracy: 0.733
[3,  1201] train_loss: 0.751  test_accuracy: 0.710
[3,  1301] train_loss: 0.732  test_accuracy: 0.716
[3,  1401] train_loss: 0.809  test_accuracy: 0.724
[3,  1501] train_loss: 0.724  test_accuracy: 0.719
[3,  1601] train_loss: 0.773  test_accuracy: 0.708
[3,  1701] train_loss: 0.745  test_accuracy: 0.741
[3,  1801] train_loss: 0.800  test_accuracy: 0.738
[3,  1901] train_loss: 0.718  test_accuracy: 0.730
[3,  2001] train_loss: 0.789  test_accuracy: 0.738
[3,  2101] train_loss: 0.731  test_accuracy: 0.725
[3,  2201] train_loss: 0.689  test_accuracy: 0.731
[3,  2301] train_loss: 0.758  test_accuracy: 0.714
[3,  2401] train_loss: 0.758  test_accuracy: 0.740
[3,  2501] train_loss: 0.739  test_accuracy: 0.744
[3,  2601] train_loss: 0.697  test_accuracy: 0.708
[3,  2701] train_loss: 0.703  test_accuracy: 0.734
[3,  2801] train_loss: 0.746  test_accuracy: 0.706
[3,  2901] train_loss: 0.783  test_accuracy: 0.706
[3,  3001] train_loss: 0.659  test_accuracy: 0.749
[3,  3101] train_loss: 0.646  test_accuracy: 0.739
[3,  3201] train_loss: 0.676  test_accuracy: 0.743
[3,  3301] train_loss: 0.654  test_accuracy: 0.748
[3,  3401] train_loss: 0.749  test_accuracy: 0.756
[3,  3501] train_loss: 0.637  test_accuracy: 0.746
[3,  3601] train_loss: 0.699  test_accuracy: 0.728
[3,  3701] train_loss: 0.653  test_accuracy: 0.735
[3,  3801] train_loss: 0.608  test_accuracy: 0.744
[3,  3901] train_loss: 0.724  test_accuracy: 0.739
[3,  4001] train_loss: 0.654  test_accuracy: 0.741
[3,  4101] train_loss: 0.711  test_accuracy: 0.745
[3,  4201] train_loss: 0.770  test_accuracy: 0.726
[3,  4301] train_loss: 0.698  test_accuracy: 0.744
[3,  4401] train_loss: 0.706  test_accuracy: 0.719
[3,  4501] train_loss: 0.674  test_accuracy: 0.752
[3,  4601] train_loss: 0.642  test_accuracy: 0.746
[3,  4701] train_loss: 0.717  test_accuracy: 0.701
[3,  4801] train_loss: 0.738  test_accuracy: 0.747
[3,  4901] train_loss: 0.583  test_accuracy: 0.752
[3,  5001] train_loss: 0.631  test_accuracy: 0.739
[3,  5101] train_loss: 0.643  test_accuracy: 0.752
[3,  5201] train_loss: 0.684  test_accuracy: 0.727
[3,  5301] train_loss: 0.590  test_accuracy: 0.729
[3,  5401] train_loss: 0.724  test_accuracy: 0.741
[3,  5501] train_loss: 0.645  test_accuracy: 0.758
[3,  5601] train_loss: 0.628  test_accuracy: 0.734
[3,  5701] train_loss: 0.571  test_accuracy: 0.746
[3,  5801] train_loss: 0.631  test_accuracy: 0.743
[3,  5901] train_loss: 0.639  test_accuracy: 0.730
[3,  6001] train_loss: 0.650  test_accuracy: 0.753
[3,  6101] train_loss: 0.605  test_accuracy: 0.730
[3,  6201] train_loss: 0.581  test_accuracy: 0.731
[4,     1] train_loss: 0.003  test_accuracy: 0.754
[4,   101] train_loss: 0.615  test_accuracy: 0.749
[4,   201] train_loss: 0.664  test_accuracy: 0.736
[4,   301] train_loss: 0.620  test_accuracy: 0.747
[4,   401] train_loss: 0.605  test_accuracy: 0.762
[4,   501] train_loss: 0.620  test_accuracy: 0.762
[4,   601] train_loss: 0.560  test_accuracy: 0.744
[4,   701] train_loss: 0.718  test_accuracy: 0.754
[4,   801] train_loss: 0.605  test_accuracy: 0.761
[4,   901] train_loss: 0.567  test_accuracy: 0.737
[4,  1001] train_loss: 0.597  test_accuracy: 0.759
[4,  1101] train_loss: 0.584  test_accuracy: 0.742
[4,  1201] train_loss: 0.629  test_accuracy: 0.736
[4,  1301] train_loss: 0.595  test_accuracy: 0.744
[4,  1401] train_loss: 0.660  test_accuracy: 0.743
[4,  1501] train_loss: 0.604  test_accuracy: 0.757
[4,  1601] train_loss: 0.647  test_accuracy: 0.763
[4,  1701] train_loss: 0.579  test_accuracy: 0.758
[4,  1801] train_loss: 0.640  test_accuracy: 0.763
[4,  1901] train_loss: 0.583  test_accuracy: 0.753
[4,  2001] train_loss: 0.620  test_accuracy: 0.733
[4,  2101] train_loss: 0.603  test_accuracy: 0.751
[4,  2201] train_loss: 0.609  test_accuracy: 0.754
[4,  2301] train_loss: 0.601  test_accuracy: 0.745
[4,  2401] train_loss: 0.612  test_accuracy: 0.759
[4,  2501] train_loss: 0.623  test_accuracy: 0.746
[4,  2601] train_loss: 0.552  test_accuracy: 0.752
[4,  2701] train_loss: 0.592  test_accuracy: 0.759
[4,  2801] train_loss: 0.613  test_accuracy: 0.747
[4,  2901] train_loss: 0.614  test_accuracy: 0.734
[4,  3001] train_loss: 0.519  test_accuracy: 0.776
[4,  3101] train_loss: 0.488  test_accuracy: 0.744
[4,  3201] train_loss: 0.537  test_accuracy: 0.746
[4,  3301] train_loss: 0.561  test_accuracy: 0.767
[4,  3401] train_loss: 0.631  test_accuracy: 0.765
[4,  3501] train_loss: 0.499  test_accuracy: 0.767
[4,  3601] train_loss: 0.583  test_accuracy: 0.777
[4,  3701] train_loss: 0.477  test_accuracy: 0.761
[4,  3801] train_loss: 0.519  test_accuracy: 0.770
[4,  3901] train_loss: 0.585  test_accuracy: 0.761
[4,  4001] train_loss: 0.541  test_accuracy: 0.751
[4,  4101] train_loss: 0.605  test_accuracy: 0.765
[4,  4201] train_loss: 0.639  test_accuracy: 0.762
[4,  4301] train_loss: 0.560  test_accuracy: 0.770
[4,  4401] train_loss: 0.569  test_accuracy: 0.763
[4,  4501] train_loss: 0.528  test_accuracy: 0.746
[4,  4601] train_loss: 0.525  test_accuracy: 0.764
[4,  4701] train_loss: 0.565  test_accuracy: 0.731
[4,  4801] train_loss: 0.601  test_accuracy: 0.762
[4,  4901] train_loss: 0.485  test_accuracy: 0.778
[4,  5001] train_loss: 0.496  test_accuracy: 0.766
[4,  5101] train_loss: 0.527  test_accuracy: 0.775
[4,  5201] train_loss: 0.570  test_accuracy: 0.733
[4,  5301] train_loss: 0.491  test_accuracy: 0.750
[4,  5401] train_loss: 0.570  test_accuracy: 0.767
[4,  5501] train_loss: 0.491  test_accuracy: 0.780
[4,  5601] train_loss: 0.515  test_accuracy: 0.773
[4,  5701] train_loss: 0.493  test_accuracy: 0.731
[4,  5801] train_loss: 0.490  test_accuracy: 0.800
[4,  5901] train_loss: 0.519  test_accuracy: 0.765
[4,  6001] train_loss: 0.502  test_accuracy: 0.785
[4,  6101] train_loss: 0.470  test_accuracy: 0.753
[4,  6201] train_loss: 0.498  test_accuracy: 0.765
[5,     1] train_loss: 0.003  test_accuracy: 0.759
[5,   101] train_loss: 0.463  test_accuracy: 0.766
[5,   201] train_loss: 0.524  test_accuracy: 0.747
[5,   301] train_loss: 0.513  test_accuracy: 0.759
[5,   401] train_loss: 0.475  test_accuracy: 0.772
[5,   501] train_loss: 0.510  test_accuracy: 0.766
[5,   601] train_loss: 0.507  test_accuracy: 0.783
[5,   701] train_loss: 0.569  test_accuracy: 0.777
[5,   801] train_loss: 0.439  test_accuracy: 0.779
[5,   901] train_loss: 0.464  test_accuracy: 0.737
[5,  1001] train_loss: 0.523  test_accuracy: 0.769
[5,  1101] train_loss: 0.470  test_accuracy: 0.780
[5,  1201] train_loss: 0.522  test_accuracy: 0.776
[5,  1301] train_loss: 0.476  test_accuracy: 0.775
[5,  1401] train_loss: 0.576  test_accuracy: 0.792
[5,  1501] train_loss: 0.455  test_accuracy: 0.784
[5,  1601] train_loss: 0.505  test_accuracy: 0.759
[5,  1701] train_loss: 0.500  test_accuracy: 0.772
[5,  1801] train_loss: 0.523  test_accuracy: 0.781
[5,  1901] train_loss: 0.474  test_accuracy: 0.766
[5,  2001] train_loss: 0.529  test_accuracy: 0.759
[5,  2101] train_loss: 0.499  test_accuracy: 0.777
[5,  2201] train_loss: 0.464  test_accuracy: 0.773
[5,  2301] train_loss: 0.499  test_accuracy: 0.778
[5,  2401] train_loss: 0.490  test_accuracy: 0.760
[5,  2501] train_loss: 0.496  test_accuracy: 0.761
[5,  2601] train_loss: 0.484  test_accuracy: 0.751
[5,  2701] train_loss: 0.531  test_accuracy: 0.778
[5,  2801] train_loss: 0.482  test_accuracy: 0.757
[5,  2901] train_loss: 0.532  test_accuracy: 0.758
[5,  3001] train_loss: 0.399  test_accuracy: 0.765
[5,  3101] train_loss: 0.426  test_accuracy: 0.760
[5,  3201] train_loss: 0.444  test_accuracy: 0.757
[5,  3301] train_loss: 0.466  test_accuracy: 0.769
[5,  3401] train_loss: 0.547  test_accuracy: 0.781
[5,  3501] train_loss: 0.389  test_accuracy: 0.761
[5,  3601] train_loss: 0.453  test_accuracy: 0.770
[5,  3701] train_loss: 0.434  test_accuracy: 0.768
[5,  3801] train_loss: 0.418  test_accuracy: 0.777
[5,  3901] train_loss: 0.512  test_accuracy: 0.786
[5,  4001] train_loss: 0.402  test_accuracy: 0.758
[5,  4101] train_loss: 0.446  test_accuracy: 0.765
[5,  4201] train_loss: 0.496  test_accuracy: 0.769
[5,  4301] train_loss: 0.454  test_accuracy: 0.765
[5,  4401] train_loss: 0.433  test_accuracy: 0.759
[5,  4501] train_loss: 0.453  test_accuracy: 0.746
[5,  4601] train_loss: 0.432  test_accuracy: 0.757
[5,  4701] train_loss: 0.490  test_accuracy: 0.754
[5,  4801] train_loss: 0.436  test_accuracy: 0.756
[5,  4901] train_loss: 0.409  test_accuracy: 0.772
[5,  5001] train_loss: 0.447  test_accuracy: 0.771
[5,  5101] train_loss: 0.411  test_accuracy: 0.764
[5,  5201] train_loss: 0.447  test_accuracy: 0.772
[5,  5301] train_loss: 0.395  test_accuracy: 0.784
[5,  5401] train_loss: 0.447  test_accuracy: 0.779
[5,  5501] train_loss: 0.397  test_accuracy: 0.776
[5,  5601] train_loss: 0.420  test_accuracy: 0.764
[5,  5701] train_loss: 0.419  test_accuracy: 0.760
[5,  5801] train_loss: 0.405  test_accuracy: 0.772
[5,  5901] train_loss: 0.490  test_accuracy: 0.762
[5,  6001] train_loss: 0.460  test_accuracy: 0.786
[5,  6101] train_loss: 0.388  test_accuracy: 0.786
[5,  6201] train_loss: 0.366  test_accuracy: 0.784
Finished Training
